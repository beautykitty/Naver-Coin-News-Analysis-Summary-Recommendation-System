{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "네이버 기사 댓글 크롤링.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[참조]\n",
        "\n",
        "네이버 기사 댓글 코드 : https://kkkapuq.tistory.com/71"
      ],
      "metadata": {
        "id": "YZAq-2R124bD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay6mU2oxzihr"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade Beautifulsoup4 selenium \n",
        "\n",
        "# !pip install selenium\n",
        "# !apt-get update\n",
        "# !apt install chromium-chromedriver\n",
        "# !cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9JZlE1k90WOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')\n"
      ],
      "metadata": {
        "id": "SpxCzfn62_9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/웹과텍스트마이닝/기말 프로젝트/Data/네이버_뉴스_코인_20220509_20220609.csv')"
      ],
      "metadata": {
        "id": "6n3JwCS0MGjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df에 기사별 댓글 추가하기 위해서 빈 열 생성\n",
        "\n",
        "df[\"Comments\"] = \"\""
      ],
      "metadata": {
        "id": "E_5NK68hsbeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 네이버 기사 댓글 링크로 변경\n",
        "# df['Link'][0][:39] + 'comment/' + df['Link'][0][39:]"
      ],
      "metadata": {
        "id": "nO-INkIPzpyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "PJwr1jN5qg2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리를 로드합니다.\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import sys\n",
        "import pprint\n",
        " "
      ],
      "metadata": {
        "id": "GgkcdOCFq6Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 여러 리스트들을 하나로 묶어 주는 함수입니다. \n",
        "def flatten(l):\n",
        "    flatList = []\n",
        "    for elem in l:\n",
        "        # if an element of a list is a list\n",
        "        # iterate over this list and add elements to flatList\n",
        "        if type(elem) == list:\n",
        "            for e in elem:\n",
        "                flatList.append(e)\n",
        "        else:\n",
        "            flatList.append(elem)\n",
        "    return flatList"
      ],
      "metadata": {
        "id": "M6Hp1yHZq43l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def naver_news_comment_scrapper(all_url):\n",
        "\n",
        "    df = pd.read_csv('/content/gdrive/MyDrive/웹과텍스트마이닝/기말 프로젝트/Data/네이버_뉴스_코인_20220509_20220609.csv')\n",
        "\n",
        "    all_comments = [] \n",
        "    for i in range(len(all_url)):\n",
        "\n",
        "            # 댓글을 달 빈 리스트를 생성합니다.\n",
        "            List = []\n",
        "\n",
        "            # 모든기사의 댓글을 모은 리스트를 생성합니다. \n",
        "            allCommetns = []\n",
        "            \n",
        "            ## 네이버 뉴스 url을 입력합니다.\n",
        "            url = all_url[i][:39] + 'comment/' + all_url[i][39:] # 네이버 기사 링크에서 기사 댓글 링크로 변경 \n",
        "            \n",
        "            # url = https://n.news.naver.com/mnews/article/comment/001/0013236507?sid=104\n",
        "\n",
        "            oid = url.split('/')[6] # oid=001\n",
        "            aid = url.split('/')[7].split('?')[0] # aid = 0013236507\n",
        "            \n",
        "            page = 1\n",
        "            header = {\"User-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36\",\n",
        "                \"referer\": url,}\n",
        "            \n",
        "            while True:\n",
        "                c_url = \"https://apis.naver.com/commentBox/cbox/web_neo_list_jsonp.json?ticket=news&templateId=default_society&pool=cbox5&_callback=jQuery1707138182064460843_1523512042464&lang=ko&country=&objectId=news\" + oid + \"%2C\" + aid + \"&categoryId=&pageSize=20&indexSize=10&groupId=&listType=OBJECT&pageType=more&page=\" + str(\n",
        "                    page) + \"&refresh=false&sort=FAVORITE\"\n",
        "                \n",
        "                # 파싱하는 단계입니다.\n",
        "                r = requests.get(c_url, headers=header)\n",
        "                cont = BeautifulSoup(r.content, \"html.parser\")\n",
        "                total_comm = str(cont).split('comment\":')[1].split(\",\")[0]\n",
        "            \n",
        "                match = re.findall('\"contents\":([^\\*]*),\"userIdNo\"', str(cont))\n",
        "                # 댓글을 리스트에 중첩합니다.\n",
        "                List.append(match)\n",
        "                # 한번에 댓글이 20개씩 보이기 때문에 한 페이지씩 몽땅 댓글을 긁어 옵니다.\n",
        "                if int(total_comm) <= ((page) * 20):\n",
        "                    break\n",
        "                else:\n",
        "                    page += 1\n",
        "\n",
        "\n",
        "            # 리스트 결과입니다.\n",
        "            all_comments.append(List)\n",
        "    \n",
        "   \n",
        "    return all_comments\n"
      ],
      "metadata": {
        "id": "f-6T_D3IkQoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 한 기사의 댓글이 20개씩 묶어있어서 기사마다 한번 더 flatten 시켜줍니다.\n",
        "\n",
        "new_a = pd.Series(a).apply(flatten)\n",
        "\n",
        "len(new_a)"
      ],
      "metadata": {
        "id": "qQ_sEWb1xFJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Comments'] = new_a "
      ],
      "metadata": {
        "id": "fYqsdtDCxFNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path =  \"/content/gdrive/My Drive/웹과텍스트마이닝/기말 프로젝트/Data/\"\n",
        "\n",
        "file_name = \"네이버_뉴스_\" + '코인_기사별_댓글' + \".csv\"\n",
        "\n",
        "file_full_path = file_path + file_name\n",
        "\n",
        "df.to_csv(file_full_path ,  index = False, encoding=\"utf-8-sig\") # utf-8-sig로 해야함!  "
      ],
      "metadata": {
        "id": "N6-nRyehxFPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mOB8CUyYyCSX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}